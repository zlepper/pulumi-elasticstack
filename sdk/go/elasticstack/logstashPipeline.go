// Code generated by the Pulumi Terraform Bridge (tfgen) Tool DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package elasticstack

import (
	"context"
	"reflect"

	"github.com/pkg/errors"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

// Creates or updates centrally managed logstash pipelines. See: https://www.elastic.co/guide/en/elasticsearch/reference/current/logstash-apis.html
//
// ## Example Usage
//
// ```go
// package main
//
// import (
// 	"fmt"
//
// 	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
// 	"github.com/zlepper/pulumi-elasticstack/sdk/go/elasticstack"
// )
//
// func main() {
// 	pulumi.Run(func(ctx *pulumi.Context) error {
// 		example, err := elasticstack.NewLogstashPipeline(ctx, "example", &elasticstack.LogstashPipelineArgs{
// 			PipelineId:  pulumi.String("test_pipeline"),
// 			Description: pulumi.String("This is an example pipeline"),
// 			Pipeline:    pulumi.String(fmt.Sprintf("input{}\nfilter{}\noutput{}\n")),
// 			PipelineMetadata: pulumi.StringMap{
// 				"type":    pulumi.String("logstash_pipeline"),
// 				"version": pulumi.String("1"),
// 			},
// 			PipelineBatchDelay:         pulumi.Int(50),
// 			PipelineBatchSize:          pulumi.Int(125),
// 			PipelineEcsCompatibility:   pulumi.String("disabled"),
// 			PipelineOrdered:            pulumi.String("auto"),
// 			PipelinePluginClassloaders: pulumi.Bool(false),
// 			PipelineUnsafeShutdown:     pulumi.Bool(false),
// 			PipelineWorkers:            pulumi.Int(1),
// 			QueueCheckpointAcks:        pulumi.Int(1024),
// 			QueueCheckpointRetry:       pulumi.Bool(true),
// 			QueueCheckpointWrites:      pulumi.Int(1024),
// 			QueueDrain:                 pulumi.Bool(false),
// 			QueueMaxBytesNumber:        pulumi.Int(1),
// 			QueueMaxBytesUnits:         pulumi.String("gb"),
// 			QueueMaxEvents:             pulumi.Int(0),
// 			QueuePageCapacity:          pulumi.String("64mb"),
// 			QueueType:                  pulumi.String("persisted"),
// 		})
// 		if err != nil {
// 			return err
// 		}
// 		ctx.Export("pipeline", example.PipelineId)
// 		return nil
// 	})
// }
// ```
//
// ## Import
//
// ```sh
//  $ pulumi import elasticstack:index/logstashPipeline:LogstashPipeline my_pipeline <cluster_uuid>/<pipeline ID>
// ```
type LogstashPipeline struct {
	pulumi.CustomResourceState

	// Description of the pipeline.
	Description pulumi.StringPtrOutput `pulumi:"description"`
	// Elasticsearch connection configuration block.
	ElasticsearchConnection LogstashPipelineElasticsearchConnectionPtrOutput `pulumi:"elasticsearchConnection"`
	// Date the pipeline was last updated.
	LastModified pulumi.StringOutput `pulumi:"lastModified"`
	// Configuration for the pipeline.
	Pipeline pulumi.StringOutput `pulumi:"pipeline"`
	// Time in milliseconds to wait for each event before sending an undersized batch to pipeline workers.
	PipelineBatchDelay pulumi.IntPtrOutput `pulumi:"pipelineBatchDelay"`
	// The maximum number of events an individual worker thread collects before executing filters and outputs.
	PipelineBatchSize pulumi.IntPtrOutput `pulumi:"pipelineBatchSize"`
	// Sets the pipeline default value for ecs_compatibility, a setting that is available to plugins that implement an ECS compatibility mode for use with the Elastic Common Schema.
	PipelineEcsCompatibility pulumi.StringPtrOutput `pulumi:"pipelineEcsCompatibility"`
	// Identifier for the pipeline.
	PipelineId pulumi.StringOutput `pulumi:"pipelineId"`
	// Optional metadata about the pipeline.
	PipelineMetadata pulumi.StringMapOutput `pulumi:"pipelineMetadata"`
	// Set the pipeline event ordering.
	PipelineOrdered pulumi.StringPtrOutput `pulumi:"pipelineOrdered"`
	// (Beta) Load Java plugins in independent classloaders to isolate their dependencies.
	PipelinePluginClassloaders pulumi.BoolPtrOutput `pulumi:"pipelinePluginClassloaders"`
	// Forces Logstash to exit during shutdown even if there are still inflight events in memory.
	PipelineUnsafeShutdown pulumi.BoolPtrOutput `pulumi:"pipelineUnsafeShutdown"`
	// The number of parallel workers used to run the filter and output stages of the pipeline.
	PipelineWorkers pulumi.IntPtrOutput `pulumi:"pipelineWorkers"`
	// The maximum number of ACKed events before forcing a checkpoint when persistent queues are enabled.
	QueueCheckpointAcks pulumi.IntPtrOutput `pulumi:"queueCheckpointAcks"`
	// When enabled, Logstash will retry four times per attempted checkpoint write for any checkpoint writes that fail. Any subsequent errors are not retried.
	QueueCheckpointRetry pulumi.BoolPtrOutput `pulumi:"queueCheckpointRetry"`
	// The maximum number of written events before forcing a checkpoint when persistent queues are enabled.
	QueueCheckpointWrites pulumi.IntPtrOutput `pulumi:"queueCheckpointWrites"`
	// When enabled, Logstash waits until the persistent queue is drained before shutting down.
	QueueDrain pulumi.BoolPtrOutput `pulumi:"queueDrain"`
	// The total capacity of the queue when persistent queues are enabled.
	QueueMaxBytesNumber pulumi.IntPtrOutput `pulumi:"queueMaxBytesNumber"`
	// Units for the total capacity of the queue when persistent queues are enabled.
	QueueMaxBytesUnits pulumi.StringPtrOutput `pulumi:"queueMaxBytesUnits"`
	// The maximum number of unread events in the queue when persistent queues are enabled.
	QueueMaxEvents pulumi.IntPtrOutput `pulumi:"queueMaxEvents"`
	// The size of the page data files used when persistent queues are enabled. The queue data consists of append-only data files separated into pages.
	QueuePageCapacity pulumi.StringPtrOutput `pulumi:"queuePageCapacity"`
	// The internal queueing model for event buffering. Options are memory for in-memory queueing, or persisted for disk-based acknowledged queueing.
	QueueType pulumi.StringPtrOutput `pulumi:"queueType"`
	// User who last updated the pipeline.
	Username pulumi.StringPtrOutput `pulumi:"username"`
}

// NewLogstashPipeline registers a new resource with the given unique name, arguments, and options.
func NewLogstashPipeline(ctx *pulumi.Context,
	name string, args *LogstashPipelineArgs, opts ...pulumi.ResourceOption) (*LogstashPipeline, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.Pipeline == nil {
		return nil, errors.New("invalid value for required argument 'Pipeline'")
	}
	if args.PipelineId == nil {
		return nil, errors.New("invalid value for required argument 'PipelineId'")
	}
	var resource LogstashPipeline
	err := ctx.RegisterResource("elasticstack:index/logstashPipeline:LogstashPipeline", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetLogstashPipeline gets an existing LogstashPipeline resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetLogstashPipeline(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *LogstashPipelineState, opts ...pulumi.ResourceOption) (*LogstashPipeline, error) {
	var resource LogstashPipeline
	err := ctx.ReadResource("elasticstack:index/logstashPipeline:LogstashPipeline", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering LogstashPipeline resources.
type logstashPipelineState struct {
	// Description of the pipeline.
	Description *string `pulumi:"description"`
	// Elasticsearch connection configuration block.
	ElasticsearchConnection *LogstashPipelineElasticsearchConnection `pulumi:"elasticsearchConnection"`
	// Date the pipeline was last updated.
	LastModified *string `pulumi:"lastModified"`
	// Configuration for the pipeline.
	Pipeline *string `pulumi:"pipeline"`
	// Time in milliseconds to wait for each event before sending an undersized batch to pipeline workers.
	PipelineBatchDelay *int `pulumi:"pipelineBatchDelay"`
	// The maximum number of events an individual worker thread collects before executing filters and outputs.
	PipelineBatchSize *int `pulumi:"pipelineBatchSize"`
	// Sets the pipeline default value for ecs_compatibility, a setting that is available to plugins that implement an ECS compatibility mode for use with the Elastic Common Schema.
	PipelineEcsCompatibility *string `pulumi:"pipelineEcsCompatibility"`
	// Identifier for the pipeline.
	PipelineId *string `pulumi:"pipelineId"`
	// Optional metadata about the pipeline.
	PipelineMetadata map[string]string `pulumi:"pipelineMetadata"`
	// Set the pipeline event ordering.
	PipelineOrdered *string `pulumi:"pipelineOrdered"`
	// (Beta) Load Java plugins in independent classloaders to isolate their dependencies.
	PipelinePluginClassloaders *bool `pulumi:"pipelinePluginClassloaders"`
	// Forces Logstash to exit during shutdown even if there are still inflight events in memory.
	PipelineUnsafeShutdown *bool `pulumi:"pipelineUnsafeShutdown"`
	// The number of parallel workers used to run the filter and output stages of the pipeline.
	PipelineWorkers *int `pulumi:"pipelineWorkers"`
	// The maximum number of ACKed events before forcing a checkpoint when persistent queues are enabled.
	QueueCheckpointAcks *int `pulumi:"queueCheckpointAcks"`
	// When enabled, Logstash will retry four times per attempted checkpoint write for any checkpoint writes that fail. Any subsequent errors are not retried.
	QueueCheckpointRetry *bool `pulumi:"queueCheckpointRetry"`
	// The maximum number of written events before forcing a checkpoint when persistent queues are enabled.
	QueueCheckpointWrites *int `pulumi:"queueCheckpointWrites"`
	// When enabled, Logstash waits until the persistent queue is drained before shutting down.
	QueueDrain *bool `pulumi:"queueDrain"`
	// The total capacity of the queue when persistent queues are enabled.
	QueueMaxBytesNumber *int `pulumi:"queueMaxBytesNumber"`
	// Units for the total capacity of the queue when persistent queues are enabled.
	QueueMaxBytesUnits *string `pulumi:"queueMaxBytesUnits"`
	// The maximum number of unread events in the queue when persistent queues are enabled.
	QueueMaxEvents *int `pulumi:"queueMaxEvents"`
	// The size of the page data files used when persistent queues are enabled. The queue data consists of append-only data files separated into pages.
	QueuePageCapacity *string `pulumi:"queuePageCapacity"`
	// The internal queueing model for event buffering. Options are memory for in-memory queueing, or persisted for disk-based acknowledged queueing.
	QueueType *string `pulumi:"queueType"`
	// User who last updated the pipeline.
	Username *string `pulumi:"username"`
}

type LogstashPipelineState struct {
	// Description of the pipeline.
	Description pulumi.StringPtrInput
	// Elasticsearch connection configuration block.
	ElasticsearchConnection LogstashPipelineElasticsearchConnectionPtrInput
	// Date the pipeline was last updated.
	LastModified pulumi.StringPtrInput
	// Configuration for the pipeline.
	Pipeline pulumi.StringPtrInput
	// Time in milliseconds to wait for each event before sending an undersized batch to pipeline workers.
	PipelineBatchDelay pulumi.IntPtrInput
	// The maximum number of events an individual worker thread collects before executing filters and outputs.
	PipelineBatchSize pulumi.IntPtrInput
	// Sets the pipeline default value for ecs_compatibility, a setting that is available to plugins that implement an ECS compatibility mode for use with the Elastic Common Schema.
	PipelineEcsCompatibility pulumi.StringPtrInput
	// Identifier for the pipeline.
	PipelineId pulumi.StringPtrInput
	// Optional metadata about the pipeline.
	PipelineMetadata pulumi.StringMapInput
	// Set the pipeline event ordering.
	PipelineOrdered pulumi.StringPtrInput
	// (Beta) Load Java plugins in independent classloaders to isolate their dependencies.
	PipelinePluginClassloaders pulumi.BoolPtrInput
	// Forces Logstash to exit during shutdown even if there are still inflight events in memory.
	PipelineUnsafeShutdown pulumi.BoolPtrInput
	// The number of parallel workers used to run the filter and output stages of the pipeline.
	PipelineWorkers pulumi.IntPtrInput
	// The maximum number of ACKed events before forcing a checkpoint when persistent queues are enabled.
	QueueCheckpointAcks pulumi.IntPtrInput
	// When enabled, Logstash will retry four times per attempted checkpoint write for any checkpoint writes that fail. Any subsequent errors are not retried.
	QueueCheckpointRetry pulumi.BoolPtrInput
	// The maximum number of written events before forcing a checkpoint when persistent queues are enabled.
	QueueCheckpointWrites pulumi.IntPtrInput
	// When enabled, Logstash waits until the persistent queue is drained before shutting down.
	QueueDrain pulumi.BoolPtrInput
	// The total capacity of the queue when persistent queues are enabled.
	QueueMaxBytesNumber pulumi.IntPtrInput
	// Units for the total capacity of the queue when persistent queues are enabled.
	QueueMaxBytesUnits pulumi.StringPtrInput
	// The maximum number of unread events in the queue when persistent queues are enabled.
	QueueMaxEvents pulumi.IntPtrInput
	// The size of the page data files used when persistent queues are enabled. The queue data consists of append-only data files separated into pages.
	QueuePageCapacity pulumi.StringPtrInput
	// The internal queueing model for event buffering. Options are memory for in-memory queueing, or persisted for disk-based acknowledged queueing.
	QueueType pulumi.StringPtrInput
	// User who last updated the pipeline.
	Username pulumi.StringPtrInput
}

func (LogstashPipelineState) ElementType() reflect.Type {
	return reflect.TypeOf((*logstashPipelineState)(nil)).Elem()
}

type logstashPipelineArgs struct {
	// Description of the pipeline.
	Description *string `pulumi:"description"`
	// Elasticsearch connection configuration block.
	ElasticsearchConnection *LogstashPipelineElasticsearchConnection `pulumi:"elasticsearchConnection"`
	// Configuration for the pipeline.
	Pipeline string `pulumi:"pipeline"`
	// Time in milliseconds to wait for each event before sending an undersized batch to pipeline workers.
	PipelineBatchDelay *int `pulumi:"pipelineBatchDelay"`
	// The maximum number of events an individual worker thread collects before executing filters and outputs.
	PipelineBatchSize *int `pulumi:"pipelineBatchSize"`
	// Sets the pipeline default value for ecs_compatibility, a setting that is available to plugins that implement an ECS compatibility mode for use with the Elastic Common Schema.
	PipelineEcsCompatibility *string `pulumi:"pipelineEcsCompatibility"`
	// Identifier for the pipeline.
	PipelineId string `pulumi:"pipelineId"`
	// Optional metadata about the pipeline.
	PipelineMetadata map[string]string `pulumi:"pipelineMetadata"`
	// Set the pipeline event ordering.
	PipelineOrdered *string `pulumi:"pipelineOrdered"`
	// (Beta) Load Java plugins in independent classloaders to isolate their dependencies.
	PipelinePluginClassloaders *bool `pulumi:"pipelinePluginClassloaders"`
	// Forces Logstash to exit during shutdown even if there are still inflight events in memory.
	PipelineUnsafeShutdown *bool `pulumi:"pipelineUnsafeShutdown"`
	// The number of parallel workers used to run the filter and output stages of the pipeline.
	PipelineWorkers *int `pulumi:"pipelineWorkers"`
	// The maximum number of ACKed events before forcing a checkpoint when persistent queues are enabled.
	QueueCheckpointAcks *int `pulumi:"queueCheckpointAcks"`
	// When enabled, Logstash will retry four times per attempted checkpoint write for any checkpoint writes that fail. Any subsequent errors are not retried.
	QueueCheckpointRetry *bool `pulumi:"queueCheckpointRetry"`
	// The maximum number of written events before forcing a checkpoint when persistent queues are enabled.
	QueueCheckpointWrites *int `pulumi:"queueCheckpointWrites"`
	// When enabled, Logstash waits until the persistent queue is drained before shutting down.
	QueueDrain *bool `pulumi:"queueDrain"`
	// The total capacity of the queue when persistent queues are enabled.
	QueueMaxBytesNumber *int `pulumi:"queueMaxBytesNumber"`
	// Units for the total capacity of the queue when persistent queues are enabled.
	QueueMaxBytesUnits *string `pulumi:"queueMaxBytesUnits"`
	// The maximum number of unread events in the queue when persistent queues are enabled.
	QueueMaxEvents *int `pulumi:"queueMaxEvents"`
	// The size of the page data files used when persistent queues are enabled. The queue data consists of append-only data files separated into pages.
	QueuePageCapacity *string `pulumi:"queuePageCapacity"`
	// The internal queueing model for event buffering. Options are memory for in-memory queueing, or persisted for disk-based acknowledged queueing.
	QueueType *string `pulumi:"queueType"`
	// User who last updated the pipeline.
	Username *string `pulumi:"username"`
}

// The set of arguments for constructing a LogstashPipeline resource.
type LogstashPipelineArgs struct {
	// Description of the pipeline.
	Description pulumi.StringPtrInput
	// Elasticsearch connection configuration block.
	ElasticsearchConnection LogstashPipelineElasticsearchConnectionPtrInput
	// Configuration for the pipeline.
	Pipeline pulumi.StringInput
	// Time in milliseconds to wait for each event before sending an undersized batch to pipeline workers.
	PipelineBatchDelay pulumi.IntPtrInput
	// The maximum number of events an individual worker thread collects before executing filters and outputs.
	PipelineBatchSize pulumi.IntPtrInput
	// Sets the pipeline default value for ecs_compatibility, a setting that is available to plugins that implement an ECS compatibility mode for use with the Elastic Common Schema.
	PipelineEcsCompatibility pulumi.StringPtrInput
	// Identifier for the pipeline.
	PipelineId pulumi.StringInput
	// Optional metadata about the pipeline.
	PipelineMetadata pulumi.StringMapInput
	// Set the pipeline event ordering.
	PipelineOrdered pulumi.StringPtrInput
	// (Beta) Load Java plugins in independent classloaders to isolate their dependencies.
	PipelinePluginClassloaders pulumi.BoolPtrInput
	// Forces Logstash to exit during shutdown even if there are still inflight events in memory.
	PipelineUnsafeShutdown pulumi.BoolPtrInput
	// The number of parallel workers used to run the filter and output stages of the pipeline.
	PipelineWorkers pulumi.IntPtrInput
	// The maximum number of ACKed events before forcing a checkpoint when persistent queues are enabled.
	QueueCheckpointAcks pulumi.IntPtrInput
	// When enabled, Logstash will retry four times per attempted checkpoint write for any checkpoint writes that fail. Any subsequent errors are not retried.
	QueueCheckpointRetry pulumi.BoolPtrInput
	// The maximum number of written events before forcing a checkpoint when persistent queues are enabled.
	QueueCheckpointWrites pulumi.IntPtrInput
	// When enabled, Logstash waits until the persistent queue is drained before shutting down.
	QueueDrain pulumi.BoolPtrInput
	// The total capacity of the queue when persistent queues are enabled.
	QueueMaxBytesNumber pulumi.IntPtrInput
	// Units for the total capacity of the queue when persistent queues are enabled.
	QueueMaxBytesUnits pulumi.StringPtrInput
	// The maximum number of unread events in the queue when persistent queues are enabled.
	QueueMaxEvents pulumi.IntPtrInput
	// The size of the page data files used when persistent queues are enabled. The queue data consists of append-only data files separated into pages.
	QueuePageCapacity pulumi.StringPtrInput
	// The internal queueing model for event buffering. Options are memory for in-memory queueing, or persisted for disk-based acknowledged queueing.
	QueueType pulumi.StringPtrInput
	// User who last updated the pipeline.
	Username pulumi.StringPtrInput
}

func (LogstashPipelineArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*logstashPipelineArgs)(nil)).Elem()
}

type LogstashPipelineInput interface {
	pulumi.Input

	ToLogstashPipelineOutput() LogstashPipelineOutput
	ToLogstashPipelineOutputWithContext(ctx context.Context) LogstashPipelineOutput
}

func (*LogstashPipeline) ElementType() reflect.Type {
	return reflect.TypeOf((**LogstashPipeline)(nil)).Elem()
}

func (i *LogstashPipeline) ToLogstashPipelineOutput() LogstashPipelineOutput {
	return i.ToLogstashPipelineOutputWithContext(context.Background())
}

func (i *LogstashPipeline) ToLogstashPipelineOutputWithContext(ctx context.Context) LogstashPipelineOutput {
	return pulumi.ToOutputWithContext(ctx, i).(LogstashPipelineOutput)
}

// LogstashPipelineArrayInput is an input type that accepts LogstashPipelineArray and LogstashPipelineArrayOutput values.
// You can construct a concrete instance of `LogstashPipelineArrayInput` via:
//
//          LogstashPipelineArray{ LogstashPipelineArgs{...} }
type LogstashPipelineArrayInput interface {
	pulumi.Input

	ToLogstashPipelineArrayOutput() LogstashPipelineArrayOutput
	ToLogstashPipelineArrayOutputWithContext(context.Context) LogstashPipelineArrayOutput
}

type LogstashPipelineArray []LogstashPipelineInput

func (LogstashPipelineArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*LogstashPipeline)(nil)).Elem()
}

func (i LogstashPipelineArray) ToLogstashPipelineArrayOutput() LogstashPipelineArrayOutput {
	return i.ToLogstashPipelineArrayOutputWithContext(context.Background())
}

func (i LogstashPipelineArray) ToLogstashPipelineArrayOutputWithContext(ctx context.Context) LogstashPipelineArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(LogstashPipelineArrayOutput)
}

// LogstashPipelineMapInput is an input type that accepts LogstashPipelineMap and LogstashPipelineMapOutput values.
// You can construct a concrete instance of `LogstashPipelineMapInput` via:
//
//          LogstashPipelineMap{ "key": LogstashPipelineArgs{...} }
type LogstashPipelineMapInput interface {
	pulumi.Input

	ToLogstashPipelineMapOutput() LogstashPipelineMapOutput
	ToLogstashPipelineMapOutputWithContext(context.Context) LogstashPipelineMapOutput
}

type LogstashPipelineMap map[string]LogstashPipelineInput

func (LogstashPipelineMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*LogstashPipeline)(nil)).Elem()
}

func (i LogstashPipelineMap) ToLogstashPipelineMapOutput() LogstashPipelineMapOutput {
	return i.ToLogstashPipelineMapOutputWithContext(context.Background())
}

func (i LogstashPipelineMap) ToLogstashPipelineMapOutputWithContext(ctx context.Context) LogstashPipelineMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(LogstashPipelineMapOutput)
}

type LogstashPipelineOutput struct{ *pulumi.OutputState }

func (LogstashPipelineOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**LogstashPipeline)(nil)).Elem()
}

func (o LogstashPipelineOutput) ToLogstashPipelineOutput() LogstashPipelineOutput {
	return o
}

func (o LogstashPipelineOutput) ToLogstashPipelineOutputWithContext(ctx context.Context) LogstashPipelineOutput {
	return o
}

// Description of the pipeline.
func (o LogstashPipelineOutput) Description() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.StringPtrOutput { return v.Description }).(pulumi.StringPtrOutput)
}

// Elasticsearch connection configuration block.
func (o LogstashPipelineOutput) ElasticsearchConnection() LogstashPipelineElasticsearchConnectionPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) LogstashPipelineElasticsearchConnectionPtrOutput {
		return v.ElasticsearchConnection
	}).(LogstashPipelineElasticsearchConnectionPtrOutput)
}

// Date the pipeline was last updated.
func (o LogstashPipelineOutput) LastModified() pulumi.StringOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.StringOutput { return v.LastModified }).(pulumi.StringOutput)
}

// Configuration for the pipeline.
func (o LogstashPipelineOutput) Pipeline() pulumi.StringOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.StringOutput { return v.Pipeline }).(pulumi.StringOutput)
}

// Time in milliseconds to wait for each event before sending an undersized batch to pipeline workers.
func (o LogstashPipelineOutput) PipelineBatchDelay() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.IntPtrOutput { return v.PipelineBatchDelay }).(pulumi.IntPtrOutput)
}

// The maximum number of events an individual worker thread collects before executing filters and outputs.
func (o LogstashPipelineOutput) PipelineBatchSize() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.IntPtrOutput { return v.PipelineBatchSize }).(pulumi.IntPtrOutput)
}

// Sets the pipeline default value for ecs_compatibility, a setting that is available to plugins that implement an ECS compatibility mode for use with the Elastic Common Schema.
func (o LogstashPipelineOutput) PipelineEcsCompatibility() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.StringPtrOutput { return v.PipelineEcsCompatibility }).(pulumi.StringPtrOutput)
}

// Identifier for the pipeline.
func (o LogstashPipelineOutput) PipelineId() pulumi.StringOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.StringOutput { return v.PipelineId }).(pulumi.StringOutput)
}

// Optional metadata about the pipeline.
func (o LogstashPipelineOutput) PipelineMetadata() pulumi.StringMapOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.StringMapOutput { return v.PipelineMetadata }).(pulumi.StringMapOutput)
}

// Set the pipeline event ordering.
func (o LogstashPipelineOutput) PipelineOrdered() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.StringPtrOutput { return v.PipelineOrdered }).(pulumi.StringPtrOutput)
}

// (Beta) Load Java plugins in independent classloaders to isolate their dependencies.
func (o LogstashPipelineOutput) PipelinePluginClassloaders() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.BoolPtrOutput { return v.PipelinePluginClassloaders }).(pulumi.BoolPtrOutput)
}

// Forces Logstash to exit during shutdown even if there are still inflight events in memory.
func (o LogstashPipelineOutput) PipelineUnsafeShutdown() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.BoolPtrOutput { return v.PipelineUnsafeShutdown }).(pulumi.BoolPtrOutput)
}

// The number of parallel workers used to run the filter and output stages of the pipeline.
func (o LogstashPipelineOutput) PipelineWorkers() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.IntPtrOutput { return v.PipelineWorkers }).(pulumi.IntPtrOutput)
}

// The maximum number of ACKed events before forcing a checkpoint when persistent queues are enabled.
func (o LogstashPipelineOutput) QueueCheckpointAcks() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.IntPtrOutput { return v.QueueCheckpointAcks }).(pulumi.IntPtrOutput)
}

// When enabled, Logstash will retry four times per attempted checkpoint write for any checkpoint writes that fail. Any subsequent errors are not retried.
func (o LogstashPipelineOutput) QueueCheckpointRetry() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.BoolPtrOutput { return v.QueueCheckpointRetry }).(pulumi.BoolPtrOutput)
}

// The maximum number of written events before forcing a checkpoint when persistent queues are enabled.
func (o LogstashPipelineOutput) QueueCheckpointWrites() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.IntPtrOutput { return v.QueueCheckpointWrites }).(pulumi.IntPtrOutput)
}

// When enabled, Logstash waits until the persistent queue is drained before shutting down.
func (o LogstashPipelineOutput) QueueDrain() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.BoolPtrOutput { return v.QueueDrain }).(pulumi.BoolPtrOutput)
}

// The total capacity of the queue when persistent queues are enabled.
func (o LogstashPipelineOutput) QueueMaxBytesNumber() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.IntPtrOutput { return v.QueueMaxBytesNumber }).(pulumi.IntPtrOutput)
}

// Units for the total capacity of the queue when persistent queues are enabled.
func (o LogstashPipelineOutput) QueueMaxBytesUnits() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.StringPtrOutput { return v.QueueMaxBytesUnits }).(pulumi.StringPtrOutput)
}

// The maximum number of unread events in the queue when persistent queues are enabled.
func (o LogstashPipelineOutput) QueueMaxEvents() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.IntPtrOutput { return v.QueueMaxEvents }).(pulumi.IntPtrOutput)
}

// The size of the page data files used when persistent queues are enabled. The queue data consists of append-only data files separated into pages.
func (o LogstashPipelineOutput) QueuePageCapacity() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.StringPtrOutput { return v.QueuePageCapacity }).(pulumi.StringPtrOutput)
}

// The internal queueing model for event buffering. Options are memory for in-memory queueing, or persisted for disk-based acknowledged queueing.
func (o LogstashPipelineOutput) QueueType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.StringPtrOutput { return v.QueueType }).(pulumi.StringPtrOutput)
}

// User who last updated the pipeline.
func (o LogstashPipelineOutput) Username() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *LogstashPipeline) pulumi.StringPtrOutput { return v.Username }).(pulumi.StringPtrOutput)
}

type LogstashPipelineArrayOutput struct{ *pulumi.OutputState }

func (LogstashPipelineArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*LogstashPipeline)(nil)).Elem()
}

func (o LogstashPipelineArrayOutput) ToLogstashPipelineArrayOutput() LogstashPipelineArrayOutput {
	return o
}

func (o LogstashPipelineArrayOutput) ToLogstashPipelineArrayOutputWithContext(ctx context.Context) LogstashPipelineArrayOutput {
	return o
}

func (o LogstashPipelineArrayOutput) Index(i pulumi.IntInput) LogstashPipelineOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *LogstashPipeline {
		return vs[0].([]*LogstashPipeline)[vs[1].(int)]
	}).(LogstashPipelineOutput)
}

type LogstashPipelineMapOutput struct{ *pulumi.OutputState }

func (LogstashPipelineMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*LogstashPipeline)(nil)).Elem()
}

func (o LogstashPipelineMapOutput) ToLogstashPipelineMapOutput() LogstashPipelineMapOutput {
	return o
}

func (o LogstashPipelineMapOutput) ToLogstashPipelineMapOutputWithContext(ctx context.Context) LogstashPipelineMapOutput {
	return o
}

func (o LogstashPipelineMapOutput) MapIndex(k pulumi.StringInput) LogstashPipelineOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *LogstashPipeline {
		return vs[0].(map[string]*LogstashPipeline)[vs[1].(string)]
	}).(LogstashPipelineOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*LogstashPipelineInput)(nil)).Elem(), &LogstashPipeline{})
	pulumi.RegisterInputType(reflect.TypeOf((*LogstashPipelineArrayInput)(nil)).Elem(), LogstashPipelineArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*LogstashPipelineMapInput)(nil)).Elem(), LogstashPipelineMap{})
	pulumi.RegisterOutputType(LogstashPipelineOutput{})
	pulumi.RegisterOutputType(LogstashPipelineArrayOutput{})
	pulumi.RegisterOutputType(LogstashPipelineMapOutput{})
}
